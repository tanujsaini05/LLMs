{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tjwin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google_api_key = \"AIzaSyBYpzx--W_OHt7Vxqy_zJ7jxgXav9am_rw\"\n",
    "\n",
    "from key import google_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[google_api_key]=google_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model ='gemini-1.5-flash',google_api_key = google_api_key,temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI offers numerous benefits in healthcare, impacting various aspects from diagnosis to treatment and administration.  Here are some key advantages:\n",
      "\n",
      "**Improved Diagnostics and Treatment:**\n",
      "\n",
      "* **Faster and more accurate diagnosis:** AI algorithms can analyze medical images (X-rays, CT scans, MRIs) and other data much faster and potentially more accurately than humans, leading to earlier detection of diseases like cancer and improved patient outcomes.\n",
      "* **Personalized medicine:** AI can analyze patient data (genetics, lifestyle, medical history) to tailor treatment plans to individual needs, optimizing effectiveness and minimizing side effects.\n",
      "* **Drug discovery and development:** AI accelerates the process of identifying potential drug candidates and predicting their efficacy and safety, reducing the time and cost of bringing new treatments to market.\n",
      "* **Robotic surgery:** AI-powered robots assist surgeons with greater precision, dexterity, and minimally invasive procedures, leading to faster recovery times and reduced complications.\n",
      "\n",
      "**Enhanced Efficiency and Productivity:**\n",
      "\n",
      "* **Administrative tasks automation:** AI can automate tasks like scheduling appointments, managing medical records, billing, and insurance claims, freeing up healthcare professionals to focus on patient care.\n",
      "* **Predictive analytics:** AI can analyze patient data to predict potential health risks and outbreaks, allowing for proactive interventions and resource allocation.\n",
      "* **Remote patient monitoring:** Wearable sensors and AI-powered platforms enable continuous monitoring of patients' vital signs, allowing for early detection of problems and timely intervention.\n",
      "* **Improved access to care:** AI-powered telehealth platforms can expand access to healthcare services, particularly in remote or underserved areas.\n",
      "\n",
      "**Other Benefits:**\n",
      "\n",
      "* **Reduced medical errors:** AI can help reduce human error in diagnosis, treatment, and medication administration.\n",
      "* **Cost reduction:** By improving efficiency, automating tasks, and optimizing resource allocation, AI can contribute to lower healthcare costs.\n",
      "* **Improved patient experience:** AI can personalize patient care, provide better communication, and offer more convenient access to services.\n",
      "* **Research and development:** AI facilitates the analysis of large datasets to accelerate medical research and the development of new treatments and technologies.\n",
      "\n",
      "\n",
      "It's important to note that while AI offers significant potential, there are also challenges to address, including data privacy concerns, algorithmic bias, the need for robust validation and regulatory oversight, and the ethical implications of using AI in healthcare decision-making.  The responsible and ethical implementation of AI is crucial to realizing its full benefits.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What are the benefits of using AI in healthcare?\"\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for LLMChain\noutput_parser\n  Input should be an instance of BaseLLMOutputParser [type=is_instance_of, input_value='menu', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/is_instance_of",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[0;32m      4\u001b[0m god_prompt \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuggest me a resturent name in \u001b[39m\u001b[38;5;132;01m{cusine}\u001b[39;00m\u001b[38;5;124m country.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m chain \u001b[38;5;241m=\u001b[39m \u001b[43mLLMChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgod_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43moutput_parser\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmenu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m chalisa_prompt \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgive me a menu for the resturent \u001b[39m\u001b[38;5;132;01m{menu}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m chain_menu \u001b[38;5;241m=\u001b[39m LLMChain(llm \u001b[38;5;241m=\u001b[39m llm, prompt \u001b[38;5;241m=\u001b[39m chalisa_prompt)\n",
      "File \u001b[1;32mc:\\Users\\tjwin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:216\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     emit_warning()\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tjwin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tjwin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    221\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for LLMChain\noutput_parser\n  Input should be an instance of BaseLLMOutputParser [type=is_instance_of, input_value='menu', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/is_instance_of"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "god_prompt = PromptTemplate.from_template(\"suggest me a resturent name in {cusine} country.\")\n",
    "chain = LLMChain(llm=llm, prompt=god_prompt,output_parser = 'menu' )\n",
    "\n",
    "chalisa_prompt = PromptTemplate.from_template(\"give me a menu for the resturent {menu}\")\n",
    "\n",
    "chain_menu = LLMChain(llm = llm, prompt = chalisa_prompt)\n",
    "\n",
    "\n",
    "topic = \"India\"\n",
    "response = chain.invoke(input=topic)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "first_prompt_template = PromptTemplate(input_variables=['cusine'],template=\"Suggest me a single restaurant name in {cuisine} country. it must be traditional.\")\n",
    "second_prompt_template = PromptTemplate(input_variables=['restaurant_name'],template=\"Give me a menu for the restaurant {restaurant_name}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_chain = LLMChain(llm = llm , prompt = first_prompt_template, output_key=\"restaurant_name\")\n",
    "second_chain = LLMChain(llm = llm , prompt = second_prompt_template,output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains = [first_chain,second_chain],\n",
    "    input_variables = [\"cuisine\"],\n",
    "    output_variables = [\"restaurant_name\",\"menu_items\"],\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'cuisine': 'Indian', 'restaurant_name': '**Tandoori Tadka**', 'menu_items': '**Tandoori Tadka**\\n\\n**Appetizers**\\n\\n* **Tandoori Chicken Tikka** - Marinated chicken grilled in a tandoor oven\\n* **Vegetable Samosas** - Crispy pastries filled with spiced vegetables\\n* **Onion Bhajis** - Fried onion fritters\\n* **Papadum** - Crispy lentil crackers\\n\\n**Main Courses**\\n\\n**Tandoori**\\n\\n* **Chicken Tikka Masala** - Grilled chicken in a creamy tomato sauce\\n* **Lamb Rogan Josh** - Lamb cooked in a spicy tomato and onion sauce\\n* **Paneer Tikka Masala** - Grilled cottage cheese in a creamy tomato sauce\\n* **Tandoori Shrimp** - Grilled shrimp marinated in yogurt and spices\\n\\n**Curries**\\n\\n* **Butter Chicken** - Chicken cooked in a creamy tomato and butter sauce\\n* **Saag Paneer** - Cottage cheese cooked in a spinach sauce\\n* **Chana Masala** - Chickpeas cooked in a spicy tomato sauce\\n* **Dal Makhani** - Black lentils cooked in a creamy tomato sauce\\n\\n**Biryani**\\n\\n* **Chicken Biryani** - Chicken cooked with rice, vegetables, and spices\\n* **Vegetable Biryani** - Vegetables cooked with rice, vegetables, and spices\\n\\n**Sides**\\n\\n* **Naan** - Soft, fluffy flatbread\\n* **Roti** - Whole wheat flatbread\\n* **Jeera Rice** - Basmati rice cooked with cumin seeds\\n* **Raita** - Yogurt-based condiment\\n\\n**Desserts**\\n\\n* **Gulab Jamun** - Sweet dumplings made from milk solids\\n* **Ras Malai** - Sweet dumplings made from cottage cheese\\n* **Kheer** - Rice pudding\\n* **Kulfi** - Indian ice cream'}\n"
     ]
    }
   ],
   "source": [
    "result = overall_chain({\"cuisine\": \"Indian\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.title('Resturant mennnuuuu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
